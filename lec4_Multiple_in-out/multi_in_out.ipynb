{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input,Model\n",
    "from keras import layers , optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data collection '''\n",
    "num_tags = 12 # Number of unique issue tags\n",
    "num_words = 10000 # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4 # Number of departments for predictions\n",
    "# Inputs \n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32')\n",
    "# Outputs \n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (Multi-heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Model Structure '''\n",
    "def DepPrio():\n",
    "   title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "   body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "   title_features = layers.LSTM(128)(title_features)\n",
    "   body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "   x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "   priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x)\n",
    "   department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x)\n",
    "\n",
    "   model = Model(inputs=[title_input, body_input, tags_input],\\\n",
    "                outputs=[priority_pred, department_pred])\n",
    "\n",
    "   model.compile(optimizer= optimizers.RMSprop(1e-3),\n",
    "                 loss={'priority': 'binary_crossentropy','department': 'categorical_crossentropy'},\n",
    "                 loss_weights=[1., 0.2]\n",
    "                 )\n",
    "   return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
